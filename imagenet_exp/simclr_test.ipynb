{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852ac39-5fca-41f3-a91b-9820c4f39220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from resnet_wider import resnet50x1, resnet50x2, resnet50x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b21902-05bc-46f4-8e5a-f58b273be45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_to_imagenet = \"/hdd2/datasets/imagenet/train\"\n",
    "val_path_to_imagenet = \"/hdd2/datasets/imagenet/val/\"\n",
    "parameter_path = \"resnet50-1x.pth\"\n",
    "num_of_sampled_classes = 100\n",
    "tree_structure = \"mintree\"\n",
    "per_class = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49344a07-30dc-4aa2-ba83-521249da7b20",
   "metadata": {},
   "source": [
    "### Load tree structure and label info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c0cdd-45dc-45f7-9df5-f86bbd411b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = nx.Graph()\n",
    "\n",
    "with open('./imagenet_' + tree_structure + '.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        nodes = line.split()\n",
    "        for node in nodes:\n",
    "            if node not in T:\n",
    "                T.add_node(node)\n",
    "        T.add_edge(*nodes)\n",
    "        \n",
    "leaves = [x for x in T.nodes() if T.degree(x) == 1]\n",
    "full_labels_loc = np.array(leaves)\n",
    "length = dict(nx.all_pairs_shortest_path_length(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56467040-5d3b-4433-a055-0a65f8b1ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./dir_label_name.json')\n",
    "map_collection = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a1572-380a-4357-acb1-331ae9bd3733",
   "metadata": {},
   "source": [
    "### Compute squared distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc0f1c-613b-4450-8da7-53713d22f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_classes = np.random.choice(len(full_labels_loc), num_of_sampled_classes, replace=False)\n",
    "sampled_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1da6f8-1418-4eba-9d65-22660a705262",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_distance_matrix = np.zeros((len(sampled_classes), len(full_labels_loc)))\n",
    "\n",
    "for i, sample_class in enumerate(sampled_classes):\n",
    "    for j, each_class_loc in enumerate(full_labels_loc):\n",
    "        sample_class_loc = map_collection[str(sample_class)][0]\n",
    "        distance = length[sample_class_loc][each_class_loc]\n",
    "        squared_distance_matrix[i][j] = distance ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91fc3a5-d73c-4ba3-894b-85541371cf00",
   "metadata": {},
   "source": [
    "### Load data from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21357f34-a62c-4c3f-be6c-69f661046883",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(train_path_to_imagenet, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "    ])),\n",
    "    batch_size=256, shuffle=True,\n",
    "    num_workers=10, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c715df46-5c15-44eb-866e-30512a939e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(val_path_to_imagenet, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "    ])),\n",
    "    batch_size=256, shuffle=True,\n",
    "    num_workers=10, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac1d153-493c-4416-a7b2-14625a2c890d",
   "metadata": {},
   "source": [
    "### Load parameters from pretrained SimCLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fecba0-7cd6-4b3c-90e0-01fc3469308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50x1()\n",
    "sd = torch.load(parameter_path, map_location='cpu')\n",
    "model.load_state_dict(sd[\"state_dict\"])\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f3a325-9488-4e1b-a5bb-e9b0b766ecd4",
   "metadata": {},
   "source": [
    "### Extract image embeddings from SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ca933-2aae-4f92-a313-4f0a4cc6254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22884f25-9e2c-4557-89f0-32b2df43087b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_embedding_collection = []\n",
    "training_ground_truth_collection = []\n",
    "for i, (images, target) in tqdm(enumerate(train_loader), total=500):\n",
    "    if i > 499: break\n",
    "    images_cuda = images.to(\"cuda:0\")\n",
    "    activation = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ## get embeddings from encoder, right before linear projection ##\n",
    "        model.avgpool.register_forward_hook(get_activation('avgpool'))\n",
    "        output = model(images_cuda)\n",
    "        embeddings = torch.squeeze(activation['avgpool']).cpu().detach().numpy()\n",
    "        training_embedding_collection.extend(embeddings)\n",
    "    training_ground_truth_collection.extend(target.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8aac18-8405-4756-9604-ad31cdf10d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_embedding_collection = np.array(training_embedding_collection)\n",
    "training_ground_truth_collection = np.array(training_ground_truth_collection)\n",
    "print(training_embedding_collection.shape, training_ground_truth_collection.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa3458-245b-4057-95b7-43865f3b2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_embedding_collection = []\n",
    "validation_ground_truth_collection = []\n",
    "for i, (images, target) in tqdm(enumerate(val_loader), total=196):\n",
    "    images_cuda = images.to(\"cuda:0\")\n",
    "    activation = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ## get embeddings from encoder, right before linear projection ##\n",
    "        model.avgpool.register_forward_hook(get_activation('avgpool'))\n",
    "        output = model(images_cuda)\n",
    "        embeddings = torch.squeeze(activation['avgpool']).cpu().detach().numpy()\n",
    "        validation_embedding_collection.extend(embeddings)\n",
    "    validation_ground_truth_collection.extend(target.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a528aa-2a6e-40ef-81b9-3ecb168eb347",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_embedding_collection = np.array(validation_embedding_collection)\n",
    "validation_ground_truth_collection = np.array(validation_ground_truth_collection)\n",
    "print(validation_embedding_collection.shape, validation_ground_truth_collection.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363bdea8-b231-49c0-a759-35453919e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = training_embedding_collection\n",
    "train_y = training_ground_truth_collection\n",
    "test_X = validation_embedding_collection\n",
    "test_y = validation_ground_truth_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e46bdd-0629-4215-8271-caa3fa275b3c",
   "metadata": {},
   "source": [
    "### Remove data outside sampled classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f026d6-48a2-4a6d-a3d6-8f75a59248b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_index = []\n",
    "for sample_class in sampled_classes:\n",
    "    sampled_index.extend(np.where(train_y == sample_class)[0][:per_class])\n",
    "sampled_index = np.array(sampled_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e201d6-4fdd-4222-83fa-46a0a48abbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_X = train_X[sampled_index]\n",
    "sampled_train_y = train_y[sampled_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc51dfa-ad5b-4854-9918-747fa6a87fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_train_X.shape, sampled_train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c2cf5-e733-443c-a464-6c607bf6ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(sampled_train_y, return_counts=True)\n",
    "print(unique_elements, counts_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d0855-401b-4d03-8327-b1c37ad255db",
   "metadata": {},
   "source": [
    "### Train logistic regression with one-vs-rest Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e9e30-6b25-4ff3-ad20-1d1ab60fa73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(random_state=0, max_iter=1000, n_jobs=-1), n_jobs=-1).fit(sampled_train_X, sampled_train_y)\n",
    "pred_prob = clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b005537-9758-4da7-92b9-69511fe8e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9cecf1-2466-4a96-a794-d9dc06e37652",
   "metadata": {},
   "source": [
    "### Argmax pred_prob to generate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf0fad-8d1a-4cde-ab86-d1c930fbc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = sampled_classes[np.argmax(pred_prob, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822e779-ee43-41b5-9df9-0fc5efa7d28b",
   "metadata": {},
   "source": [
    "### Compute average squared distance over all the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3a40b-a39b-4a58-99cc-bf4b48efef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_squared_distance = 0\n",
    "for pred, gt in zip(prediction, test_y):\n",
    "    pred_index = np.where(sampled_classes == pred)[0][0]\n",
    "    avg_squared_distance += squared_distance_matrix[pred_index][gt]\n",
    "avg_squared_distance = avg_squared_distance / len(test_y)\n",
    "print(\"SimCLR + LG, AVG Squared Distance: \", avg_squared_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb56035-bf8b-4820-a5dc-e057d4846ffc",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6aa3b-858f-4b59-a6b2-ee123b038f64",
   "metadata": {},
   "source": [
    "### With proposed label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9db044-29fe-45a9-bc65-ea648e6ac68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_w_label_model = np.argmin(np.dot(pred_prob, squared_distance_matrix), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e3d2c-20d8-425a-9e41-09ec9e534e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def fréchet_variance(y, L, w, d):\n",
    "    v = 0\n",
    "    for i, sample_class in enumerate(L):\n",
    "        v += w[i] * (d[i][y])\n",
    "    return v\n",
    "\n",
    "def fréchet_mean(L, w, d):\n",
    "    Y = np.arange(len(full_labels_loc))\n",
    "    return np.argmin([fréchet_variance(y, L, w, d) for y in Y])\n",
    "    \n",
    "prediction_w_label_model = []\n",
    "for p_num, (prob, gt) in tqdm(enumerate(zip(pred_prob, test_y)), total=len(test_y)):\n",
    "    argmin_y = fréchet_mean(sampled_classes, prob, squared_distance_matrix)\n",
    "    prediction_w_label_model.append(argmin_y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35785ef4-8c7c-479e-8dca-37b69e0b8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_squared_distance_w_label_model = 0\n",
    "for pred, gt in zip(prediction_w_label_model, test_y):\n",
    "    pred_loc = map_collection[str(pred)][0]\n",
    "    gt_loc = map_collection[str(gt)][0]\n",
    "    distance = length[pred_loc][gt_loc]\n",
    "    avg_squared_distance_w_label_model += distance ** 2\n",
    "avg_squared_distance_w_label_model = avg_squared_distance_w_label_model / len(test_y)\n",
    "print(\"SimCLR + LG + Label Model, AVG Squared Distance: \", avg_squared_distance_w_label_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432db60-0c7c-4002-92a3-e50aca733f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40cdac-62f7-4a57-8d6a-a507b52916e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simclr",
   "language": "python",
   "name": "simclr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
