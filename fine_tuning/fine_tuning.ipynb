{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy import typing as npt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our goal is to fine-tune the prediction probabilities sent into Loki. \n",
    "# We will explore different ways to backpropagate through the locus of the FrÃ©chet mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random simplex vector of dim K\n",
    "# Create random tree graph with K nodes (or leaves?)\n",
    "\n",
    "# BASELINE SANITY CHECK -- get gradients of the simplex vector from \n",
    "# cross entropy loss with some random label \n",
    "# \n",
    "# OUR METHOD -- get gradients of the simplex vector from our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Utility functions... \n",
    "\n",
    "def generate_batch(k:int=100, bs:int=1, soft:bool=False) -> torch.FloatTensor:\n",
    "    ''' \n",
    "    k: synthetic observed label space dimension \n",
    "    bs: synthetic batch size\n",
    "    \n",
    "    returns unnormalized synthetic logits\n",
    "\n",
    "    Generate a synthetic batch of softmax outputs\n",
    "    NOTE we want to ultimately obtain gradients for these\n",
    "    '''\n",
    "    preds = torch.randn(bs, k, requires_grad=True)#.softmax(dim=1)\n",
    "    if soft:\n",
    "        targets = torch.randn(bs, k).softmax(dim=1)\n",
    "    else:\n",
    "        targets = torch.empty(bs, dtype=torch.long).random_(k)\n",
    "    return preds, targets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline (gradient sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7404725551605225\n",
      "Gradient of logits: \n",
      "tensor([[ 1.9224e-05,  6.7176e-04,  3.0347e-05,  ...,  5.0783e-05,\n",
      "          3.2975e-05,  3.6367e-06],\n",
      "        [ 1.8773e-04,  5.4567e-05,  6.7605e-05,  ..., -9.3582e-04,\n",
      "          3.4379e-05,  1.9915e-04],\n",
      "        [ 1.2522e-04,  4.8774e-05,  4.3607e-05,  ...,  4.4643e-05,\n",
      "         -5.3026e-04,  3.4537e-05],\n",
      "        ...,\n",
      "        [ 2.3040e-04,  1.1506e-04,  2.2619e-05,  ...,  9.5830e-05,\n",
      "          2.8217e-05,  1.2264e-04],\n",
      "        [ 1.3104e-04,  1.3216e-04,  2.0377e-05,  ...,  7.5179e-05,\n",
      "         -8.8917e-04,  7.8006e-05],\n",
      "        [ 3.4768e-05, -9.4152e-04,  8.7884e-05,  ...,  7.0787e-05,\n",
      "          2.2634e-05,  7.2271e-05]])\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "bs = 1024\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "preds, targets = generate_batch(k=k, bs=bs)\n",
    "loss = loss(preds, targets)\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Gradient of logits: \\n{preds.grad}\")\n",
    "\n",
    "preds.grad = None # clear the gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay cool, so we want something like this where we have logit gradients, but where we're fine-tuning with something that looks more like the Loki prediction rule..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 1: fine-tune using class-wise probabilities from Loki\n",
    "\n",
    "Assume we can get the probability vectors that correspond to a certain class under loki (which might be wildly non-unique), then fine tune using this.\n",
    "Trivially, we have gradients in this case because it's just soft-target training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 10\n",
    "# bs = 4\n",
    "\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# preds, targets = generate_batch(k=k, bs=bs, soft=True)\n",
    "# output = loss(preds, targets)\n",
    "# output.backward()\n",
    "\n",
    "# print(f\"Loss: {output}\")\n",
    "# print(f\"Gradient of logits: \\n{preds.grad}\")\n",
    "\n",
    "# NOTE okay rip, I guess this version of pytorch doesn't support this even though it's in their documentation. Moving on because this idea probably wasn't going to work anyway, due to potentially many distict regions of simplex that correspond to the same classes. Consider an internal node in a tree and all possible paths that pass through that node. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 2: crude Euclidean approximation using MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = nx.random_tree(n=k, seed=0)\n",
    "nx.draw(T, with_labels=True)\n",
    "plt.title(\"Random tree metric space\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding reconstruction error: 0.1220\n"
     ]
    }
   ],
   "source": [
    "distances = nx.floyd_warshall_numpy(T)\n",
    "\n",
    "plt.matshow(distances)\n",
    "plt.title(\"Original distances\")\n",
    "plt.show()\n",
    "\n",
    "embedding_dim = 4\n",
    "embedder = MDS(n_components=embedding_dim, dissimilarity='precomputed')\n",
    "y_emb = embedder.fit_transform(distances)\n",
    "\n",
    "reconstructed_distances = cdist(y_emb, y_emb)\n",
    "plt.matshow(reconstructed_distances)\n",
    "plt.title(\"Reconstructed distances\")\n",
    "plt.show()\n",
    "\n",
    "# MAE of reconstructed distances. Not terrible, not amazing. \n",
    "emb_rec_err = np.mean(np.abs(reconstructed_distances - distances))\n",
    "print(f\"Embedding reconstruction error: {emb_rec_err:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we want to set up the fine tuning problem so that we can try to reconstruct held-out clases that are in the locus of the held-in classes... \n",
    "\n",
    "Let's just try to reconstruct the top three nodes with the highest degree in our random tree for now. We know that at leas the top node is in the locus of the rest of the tree, for nontrivial trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "assert(top_k <= k)\n",
    "\n",
    "sortlist = sorted(T.degree, key=lambda x: x[1], reverse=True)\n",
    "in_locus_labels = [sortlist[i][0] for i in range(top_k)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter our dataset in the correct way so that we can create our in-locus fine tuning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fine tuning dataset by filtering: \n",
    "# axis 0 of X,Y by in_locus_labels and\n",
    "# axis 1 of X the complement of in_locus_labels\n",
    "# NOTE this will be reused for most of our methods\n",
    "\n",
    "preds, targets = generate_batch(k=k, bs=bs)\n",
    "\n",
    "ft_preds = []\n",
    "ft_targets = []\n",
    "locus_boundary = np.sort(list(set(np.arange(k)) - set(in_locus_labels)))\n",
    "\n",
    "for i in range(bs):\n",
    "    if targets[i] in in_locus_labels:\n",
    "        ft_preds.append(preds[i])\n",
    "        ft_targets.append(targets[i])\n",
    "\n",
    "ft_preds = torch.stack(ft_preds)[:, locus_boundary]\n",
    "ft_targets = torch.stack(ft_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.886120557785034\n",
      "Gradient of logits: \n",
      "tensor([[ 0.0000, -0.0011, -0.0010,  ...,  0.0003,  0.0033, -0.0029],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "def euclidean_relaxed_objective_with_logits(\n",
    "        input: torch.FloatTensor, \n",
    "        target: torch.LongTensor, \n",
    "        locus_bd: torch.LongTensor, \n",
    "        embedding: torch.LongTensor) -> torch.FloatTensor:\n",
    "    '''\n",
    "    preds: prediction logits\n",
    "    targets: indices of the targets\n",
    "    locus_boundary: the classes that we use to reconstruct the targets\n",
    "    embedding: naÃ¯ve MDS embedding of the metric space\n",
    "\n",
    "    returns the loss. \n",
    "    '''\n",
    "    rec = input.softmax(dim=1) @ y_emb[locus_bd]\n",
    "    diff = y_emb[target] - rec\n",
    "    rec_dist = torch.linalg.norm(diff, dim=1) ** 2\n",
    "    loss = torch.mean(rec_dist)\n",
    "    return loss\n",
    "\n",
    "\n",
    "y_emb = torch.Tensor(y_emb)\n",
    "locus_bd = torch.LongTensor(locus_boundary.astype(np.int64))\n",
    "loss = euclidean_relaxed_objective_with_logits(\n",
    "    ft_preds, ft_targets, locus_bd, y_emb)\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Gradient of logits: \\n{preds.grad}\")\n",
    "\n",
    "preds.grad = None # clear the gradients\n",
    "ft_preds.grad = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also implement a pseudo-Euclidean version of this, but in the interest of time, let's skip it and go straight to the polytope projection approach. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea 3: polytope projection using SPIGOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8.002544403076172\n",
      "Gradient of logits: \n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ..., -8.7891,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -8.7891,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -8.7891],\n",
      "        [ 0.0000, -8.7891,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "torch.Size([1024, 10])\n"
     ]
    }
   ],
   "source": [
    "# Since SPIGOT will output hard predictions, we must smooth the predictions\n",
    "# in order for the cross entropy loss to be well-defined.  \n",
    "def smooth_hard_preds(preds, k, eps=0.1):\n",
    "    bs = preds.shape[0]\n",
    "    rest = (1 / (k - 1)) * eps\n",
    "    p_rest = torch.ones((bs, k)) * rest\n",
    "    onehot = torch.eye(k)[preds]\n",
    "    onehot_scaled = onehot * ((1.0 - eps) - (1 / (k - 1)) * eps)\n",
    "    p_smooth = p_rest + onehot_scaled\n",
    "    assert((p_smooth.argmax(dim=1) == preds).all())\n",
    "    # Important that p_smooth requires grad so that it can be used in SPIGOT\n",
    "    p_smooth.requires_grad = True\n",
    "    return p_smooth\n",
    "\n",
    "\n",
    "loss = nn.NLLLoss() # Use NLL since we don't use logits\n",
    "with torch.no_grad():\n",
    "    preds_, targets = generate_batch(k=k, bs=bs)\n",
    "    preds = smooth_hard_preds(preds_.argmax(dim=1), k=k, eps=0.001)\n",
    "\n",
    "# NLL loss takes logsoftmax input\n",
    "loss = loss(torch.log(preds), targets)\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Gradient of logits: \\n{preds.grad}\")\n",
    "\n",
    "print(preds.grad.shape)\n",
    "\n",
    "preds.grad = None # clear the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LokiStraightThroughEstimator(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, probs: torch.FloatTensor, dists: torch.FloatTensor):\n",
    "        k = dists.shape[0]\n",
    "        onehot = torch.eye(k)\n",
    "        \n",
    "        # Compute S(x) = vector of negative FrÃ©chet variances\n",
    "        s = -probs @ (dists ** 2)\n",
    "\n",
    "        # Intermediate decoding step\n",
    "        with torch.no_grad():\n",
    "            z_hat_int = s.argmax(dim=1)\n",
    "            z_hat_onehot = onehot[z_hat_int]\n",
    "\n",
    "        # Important to ensure that z_hat_smoothed gets gradients from the loss\n",
    "        z_hat_onehot.requires_grad = True\n",
    "        return z_hat_onehot\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.FloatTensor):\n",
    "        return grad_output, None, None\n",
    "    \n",
    "def loki_ste_predict(probs, dists):\n",
    "    loki = LokiStraightThroughEstimator()\n",
    "    return loki.apply(probs, dists)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_simplex(y):\n",
    "    ''' From http://www.mcduplessis.com/index.php/2016/08/22/fast-projection-onto-a-simplex-python/\n",
    "    '''\n",
    "    d = len(y)\n",
    "    a = torch.ones(d)\n",
    "    idx = torch.argsort(y)\n",
    "    evalpL = lambda k: torch.sum((y[idx[k:]] - y[idx[k]])) - 1\n",
    "\n",
    "    def bisectsearch():\n",
    "        idxL, idxH = 0, d-1\n",
    "        L = evalpL(idxL)\n",
    "        H = evalpL(idxH)\n",
    "        if L < 0:\n",
    "            return idxL\n",
    "        while (idxH - idxL) > 1:\n",
    "            iMid = int((idxL + idxH) / 2)\n",
    "            M = evalpL(iMid)\n",
    "            if M > 0:\n",
    "                idxL, L = iMid, M\n",
    "            else:\n",
    "                idxH, H = iMid, M\n",
    "        return idxH\n",
    "        \n",
    "    k = bisectsearch()\n",
    "    lam = (torch.sum(y[idx[k:]]) - 1) / (d - k)\n",
    "    x = np.maximum(0, y - lam)\n",
    "    return x\n",
    "\n",
    "class LokiPolytopeEstimator(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, probs: torch.FloatTensor,\n",
    "                dists: torch.FloatTensor, eta: float):\n",
    "        k = dists.shape[0]\n",
    "        eta = torch.tensor(eta)\n",
    "        onehot = torch.eye(k)\n",
    "        \n",
    "        # Compute S(x) = vector of negative FrÃ©chet variances\n",
    "        s = -probs @ (dists ** 2)\n",
    "\n",
    "        # Intermediate decoding step\n",
    "        with torch.no_grad():\n",
    "            z_hat_int = s.argmax(dim=1)\n",
    "            z_hat_onehot = onehot[z_hat_int]\n",
    "        ctx.save_for_backward(z_hat_onehot, eta)\n",
    "\n",
    "        # Important to ensure that z_hat_smoothed gets gradients from the loss\n",
    "        z_hat_onehot.requires_grad = True\n",
    "        return z_hat_onehot\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.FloatTensor):\n",
    "        z_hat_onehot, eta, = ctx.saved_tensors\n",
    "        z_unproj = z_hat_onehot - (eta * grad_output)\n",
    "\n",
    "        # TODO project z_unproj onto the unit simplex\n",
    "        # NOTE that the unit simplex is just the relaxed convex polytope of\n",
    "        # the one-hot vectors. \n",
    "        # NOTE SOFTMAX IS A QUICK-AND-DIRTY NON-OPTIMAL PROJECTION...\n",
    "        #z_proj = z_unproj.softmax(dim=1)\n",
    "        # NOTE this is the actual projection but it's slower because it's\n",
    "        # not batched! \n",
    "        b = z_unproj.shape[0]\n",
    "        z_proj = torch.stack([proj_simplex(z_unproj[i]) for i in range(b)])\n",
    "        \n",
    "        delta_s = z_hat_onehot - z_proj\n",
    "        return delta_s, None, None, None\n",
    "    \n",
    "def loki_polytope_predict(probs, dists, eta=0.01):\n",
    "    loki = LokiPolytopeEstimator()\n",
    "    return loki.apply(probs, dists, eta)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8.269262313842773\n",
      "Gradient of logits: \n",
      "tensor([[-2.7558e-04, -4.6034e-03, -4.4226e-04,  ..., -1.5093e-03,\n",
      "         -3.7005e-04, -2.5563e-03],\n",
      "        [-3.4898e-04, -1.2809e-04, -7.6112e-05,  ..., -1.4491e-04,\n",
      "         -9.9110e-04, -5.9959e-05],\n",
      "        [-1.5978e-04, -3.6445e-03, -3.9803e-04,  ..., -4.3914e-03,\n",
      "         -3.6901e-04, -1.4279e-05],\n",
      "        ...,\n",
      "        [-6.1420e-04, -7.0558e-04, -1.8778e-04,  ..., -1.2134e-03,\n",
      "         -1.9822e-04, -6.7477e-04],\n",
      "        [ 6.6623e-04,  7.9820e-04,  2.6809e-03,  ...,  2.5414e-04,\n",
      "          2.5603e-04,  8.3534e-04],\n",
      "        [-3.4556e-05, -1.6191e-05, -1.5786e-05,  ..., -2.6472e-05,\n",
      "         -9.9330e-06, -3.1045e-03]])\n"
     ]
    }
   ],
   "source": [
    "loss = nn.NLLLoss()\n",
    "\n",
    "logits, targets = generate_batch(k=k, bs=bs)\n",
    "probs = logits.softmax(dim=1)\n",
    "preds = loki_polytope_predict(probs, torch.Tensor(distances))\n",
    "\n",
    "# Apply \"label smoothing\" to the hard predictions\n",
    "# so that downstream loss remains well-defined\n",
    "eps=0.001\n",
    "smooth_onehot = torch.ones(k, k) * (1 / (k - 1)) * eps\n",
    "smooth_onehot += torch.eye(k) * ((1 - eps) - (1 / (k - 1)) * eps)\n",
    "preds_smoothed = preds @ smooth_onehot\n",
    "\n",
    "# NLL loss takes logsoftmax input\n",
    "loss = loss(torch.log(preds_smoothed), targets)\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Gradient of logits: \\n{logits.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [[0.2 0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2 0.2]] [[0.2 0.4 0.6 0.8 1. ]\n",
      " [0.2 0.4 0.6 0.8 1. ]]\n",
      "[[0.2 0.4 0.6 0.8 1. ]\n",
      " [0.2 0.4 0.6 0.8 1. ]]\n",
      "[1 4]\n",
      "[[-0.3  0. ]\n",
      " [-0.3  0. ]]\n",
      "[1 4]\n",
      "[[0.2 0.4 0.6 0.8 1. ]\n",
      " [0.2 0.4 0.6 0.8 1. ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [0.2, 0.2, 0.2, 0.2, 0.2]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidean_proj_simplex(v, s=1):\n",
    "    \"\"\" Compute the Euclidean projection on a positive simplex\n",
    "    Solves the optimisation problem (using the algorithm from [1]):\n",
    "        min_w 0.5 * || w - v ||_2^2 , s.t. \\sum_i w_i = s, w_i >= 0 \n",
    "    Parameters\n",
    "    ----------\n",
    "    v: (n,) numpy array,\n",
    "       n-dimensional vector to project\n",
    "    s: int, optional, default: 1,\n",
    "       radius of the simplex\n",
    "    Returns\n",
    "    -------\n",
    "    w: (n,) numpy array,\n",
    "       Euclidean projection of v on the simplex\n",
    "    Notes\n",
    "    -----\n",
    "    The complexity of this algorithm is in O(n log(n)) as it involves sorting v.\n",
    "    Better alternatives exist for high-dimensional sparse vectors (cf. [1])\n",
    "    However, this implementation still easily scales to millions of dimensions.\n",
    "    References\n",
    "    ----------\n",
    "    [1] Efficient Projections onto the .1-Ball for Learning in High Dimensions\n",
    "        John Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra.\n",
    "        International Conference on Machine Learning (ICML 2008)\n",
    "        http://www.cs.berkeley.edu/~jduchi/projects/DuchiSiShCh08.pdf\n",
    "    \"\"\"\n",
    "    assert s > 0, \"Radius s must be strictly positive (%d <= 0)\" % s\n",
    "    bs, n = v.shape  # will raise ValueError if v is not 1-D\n",
    "    # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    u = np.sort(v, axis=-1)[::-1]\n",
    "    cssv = np.cumsum(u, axis=-1)\n",
    "\n",
    "\n",
    "    print(n, u, cssv)\n",
    "\n",
    "    print(u * np.arange(1, n+1))\n",
    "    print( np.stack(np.nonzero(u * np.arange(1, n+1) > (cssv - s)))[:, -1] )\n",
    "\n",
    "    # get the number of > 0 components of the optimal solution\n",
    "    rho = np.stack(np.nonzero(u * np.arange(1, n+1) > (cssv - s)))[:, -1]\n",
    "\n",
    "    print((cssv[:, rho] - s) / (rho + 1))\n",
    "\n",
    "    # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    theta = (np.diagonal(cssv[:, rho]) - s) / (rho + 1)\n",
    "\n",
    "\n",
    "    print(rho)\n",
    "    print(cssv)\n",
    "    #print(theta)\n",
    "    #print(v)\n",
    "    \n",
    "    # compute the projection by thresholding v using theta\n",
    "    w = (v - theta[:, None]).clip(min=0)\n",
    "    return w\n",
    "\n",
    "v = np.ones((2, 5)) / 5\n",
    "euclidean_proj_simplex(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0.2 0.2 0.2 0.2 0.2] [0.2 0.4 0.6 0.8 1. ]\n",
      "4\n",
      "0.0\n",
      "[0.2 0.2 0.2 0.2 0.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidean_proj_simplex(v, s=1):\n",
    "    \"\"\" Compute the Euclidean projection on a positive simplex\n",
    "    Solves the optimisation problem (using the algorithm from [1]):\n",
    "        min_w 0.5 * || w - v ||_2^2 , s.t. \\sum_i w_i = s, w_i >= 0 \n",
    "    Parameters\n",
    "    ----------\n",
    "    v: (n,) numpy array,\n",
    "       n-dimensional vector to project\n",
    "    s: int, optional, default: 1,\n",
    "       radius of the simplex\n",
    "    Returns\n",
    "    -------\n",
    "    w: (n,) numpy array,\n",
    "       Euclidean projection of v on the simplex\n",
    "    Notes\n",
    "    -----\n",
    "    The complexity of this algorithm is in O(n log(n)) as it involves sorting v.\n",
    "    Better alternatives exist for high-dimensional sparse vectors (cf. [1])\n",
    "    However, this implementation still easily scales to millions of dimensions.\n",
    "    References\n",
    "    ----------\n",
    "    [1] Efficient Projections onto the .1-Ball for Learning in High Dimensions\n",
    "        John Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra.\n",
    "        International Conference on Machine Learning (ICML 2008)\n",
    "        http://www.cs.berkeley.edu/~jduchi/projects/DuchiSiShCh08.pdf\n",
    "    \"\"\"\n",
    "    assert s > 0, \"Radius s must be strictly positive (%d <= 0)\" % s\n",
    "    n, = v.shape  # will raise ValueError if v is not 1-D\n",
    "    # check if we are already on the simplex\n",
    "    # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    u = np.sort(v)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "\n",
    "\n",
    "    print(n, u, cssv)\n",
    "\n",
    "\n",
    "    # get the number of > 0 components of the optimal solution\n",
    "    rho = np.nonzero(u * np.arange(1, n+1) > (cssv - s))[0][-1]\n",
    "    # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    theta = float(cssv[rho] - s) / rho\n",
    "\n",
    "    print(rho)\n",
    "    print(theta)\n",
    "    print(v)\n",
    "\n",
    "    # compute the projection by thresholding v using theta\n",
    "    w = (v - theta).clip(min=0)\n",
    "    return w\n",
    "\n",
    "v = np.ones(5) / 5\n",
    "euclidean_proj_simplex(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0d00a037b7aa4b8a2be5e93e47a093862d1c78b064fe50e46fc81e25196f4b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
